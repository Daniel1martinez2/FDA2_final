{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, models, transforms\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import models, transforms\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directory paths\n",
    "data_dir = 'AF_dataset'\n",
    "train_dir = os.path.join(data_dir, 'train')\n",
    "test_dir = os.path.join(data_dir, 'test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'AF_dataset'\n",
    "train_info = pd.read_csv(f'{path}/train.csv')\n",
    "\n",
    "X = train_info[['filename', 'xmin', 'ymin', 'xmax', 'ymax']]\n",
    "y = train_info['class_id']\n",
    "\n",
    "data = pd.concat([X, y], axis=1)\t\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "train_data = pd.concat([X_train, y_train], axis=1)\n",
    "test_data = pd.concat([X_test, y_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_test_img_folder(train_df, test_df):\n",
    "    splits = {'train': train_df, 'test': test_df}\n",
    "    for split, df in splits.items():\n",
    "        for i, row in df.iterrows():\n",
    "            source_file = f'{path}/images/{row[\"filename\"]}'\n",
    "            class_name = 'pinguin' if row['class_id'] == 1 else 'turtle'\n",
    "            destination_folder = f'data/{split}'\n",
    "            os.makedirs(destination_folder, exist_ok=True)\n",
    "            destination_file = os.path.join(destination_folder)\n",
    "            shutil.copy(source_file, destination_file)\n",
    "\n",
    "\n",
    "create_train_test_img_folder(train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = 'data'\n",
    "train_dir = os.path.join(root_dir, 'train')\n",
    "test_dir = os.path.join(root_dir, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoundingBoxDataset(Dataset):\n",
    "    def __init__(self, data, root_dir, transform=None):\n",
    "        self.data = data\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        img_name = os.path.join(self.root_dir, row['filename'])\n",
    "        image = plt.imread(img_name)\n",
    "        \n",
    "        # Apply transformations if any\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Extract bounding box coordinates\n",
    "        bbox = torch.tensor([row['xmin'], row['ymin'], row['xmax'], row['ymax']])\n",
    "        \n",
    "        # Extract class label\n",
    "        label = torch.tensor(row['class_id'] - 1)  # Subtract 1 to make labels 0-based\n",
    "\n",
    "        return image, label, bbox\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data transformations\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.Resize((255, 255)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # Pretrained VGG-16 mean and std\n",
    "])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((255, 255)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "# Load train and test data\n",
    "train_dataset = BoundingBoxDataset(train_data, root_dir=train_dir, transform=train_transforms)\n",
    "test_dataset = BoundingBoxDataset(test_data, root_dir=test_dir, transform=test_transforms)\n",
    "\n",
    "# Data loaders\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielmartinezvillegas/anaconda3/envs/tf-macos/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/danielmartinezvillegas/anaconda3/envs/tf-macos/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Load pretrained VGG-16 model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "base_model = models.vgg16(pretrained=True)\n",
    "\n",
    "# Freeze the base model layers\n",
    "for param in base_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Modify the classifier for dual outputs\n",
    "class MultiTaskVGG16(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiTaskVGG16, self).__init__()\n",
    "        \n",
    "        # Base feature extractor\n",
    "        self.features = base_model.features\n",
    "        self.avgpool = base_model.avgpool\n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        # Shared fully connected layers\n",
    "        self.shared_fc = nn.Sequential(\n",
    "            nn.Linear(512 * 7 * 7, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5)\n",
    "        )\n",
    "        \n",
    "        # Classification head\n",
    "        self.classifier = nn.Linear(4096, 2)  # For 2 classes: penguin and turtle\n",
    "        \n",
    "        # Bounding box regression head\n",
    "        self.regressor = nn.Linear(4096, 4)  # For 4 coordinates: xmin, ymin, xmax, ymax\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.shared_fc(x)\n",
    "        \n",
    "        class_output = self.classifier(x)\n",
    "        bbox_output = self.regressor(x)\n",
    "        \n",
    "        return class_output, bbox_output\n",
    "\n",
    "# Initialize model\n",
    "model = MultiTaskVGG16().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss functions\n",
    "classification_criterion = nn.CrossEntropyLoss()\n",
    "regression_criterion = nn.MSELoss()\n",
    "\n",
    "# Optimizer (only fine-tuning the final layers)\n",
    "optimizer = Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train(model, train_loader, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels, bboxes in tqdm(train_loader):\n",
    "        images, labels, bboxes = images.to(device), labels.to(device), bboxes.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        class_outputs, bbox_outputs = model(images)\n",
    "        \n",
    "        # Compute losses\n",
    "        class_loss = classification_criterion(class_outputs, labels)\n",
    "        bbox_loss = regression_criterion(bbox_outputs, bboxes.float())\n",
    "        loss = class_loss + bbox_loss  # Combine losses\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * images.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    return epoch_loss\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate(model, test_loader, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    all_preds, all_labels = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels, bboxes in tqdm(test_loader):\n",
    "            images, labels, bboxes = images.to(device), labels.to(device), bboxes.to(device)\n",
    "            \n",
    "            class_outputs, bbox_outputs = model(images)\n",
    "            \n",
    "            # Compute losses\n",
    "            class_loss = classification_criterion(class_outputs, labels)\n",
    "            bbox_loss = regression_criterion(bbox_outputs, bboxes.float())\n",
    "            loss = class_loss + bbox_loss\n",
    "            \n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            \n",
    "            # Store predictions and labels for accuracy calculation\n",
    "            preds = class_outputs.argmax(dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    epoch_loss = running_loss / len(test_loader.dataset)\n",
    "    return epoch_loss, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [01:05<00:00,  2.72s/it]\n",
      "100%|██████████| 6/6 [00:14<00:00,  2.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 34200.6894\n",
      "Validation Loss: 15297.0631\n",
      "Validation Accuracy: 0.8947\n",
      "Saved Best Model!\n",
      "Epoch 2/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [01:04<00:00,  2.71s/it]\n",
      "100%|██████████| 6/6 [00:14<00:00,  2.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 10102.2517\n",
      "Validation Loss: 7444.7819\n",
      "Validation Accuracy: 0.6632\n",
      "Epoch 3/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [01:04<00:00,  2.70s/it]\n",
      "100%|██████████| 6/6 [00:14<00:00,  2.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 6070.7344\n",
      "Validation Loss: 6915.9948\n",
      "Validation Accuracy: 0.9158\n",
      "Saved Best Model!\n",
      "Epoch 4/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [01:04<00:00,  2.68s/it]\n",
      "100%|██████████| 6/6 [00:14<00:00,  2.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 4255.7390\n",
      "Validation Loss: 6086.0506\n",
      "Validation Accuracy: 0.8737\n",
      "Epoch 5/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [01:04<00:00,  2.68s/it]\n",
      "100%|██████████| 6/6 [00:14<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 3350.0308\n",
      "Validation Loss: 5632.1335\n",
      "Validation Accuracy: 0.8947\n",
      "Epoch 6/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [01:04<00:00,  2.69s/it]\n",
      "100%|██████████| 6/6 [00:14<00:00,  2.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2944.1593\n",
      "Validation Loss: 5696.8212\n",
      "Validation Accuracy: 0.9368\n",
      "Saved Best Model!\n",
      "Epoch 7/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [01:04<00:00,  2.69s/it]\n",
      "100%|██████████| 6/6 [00:14<00:00,  2.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2449.7171\n",
      "Validation Loss: 6155.6013\n",
      "Validation Accuracy: 0.9263\n",
      "Epoch 8/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [01:04<00:00,  2.68s/it]\n",
      "100%|██████████| 6/6 [00:14<00:00,  2.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2633.5751\n",
      "Validation Loss: 5847.4013\n",
      "Validation Accuracy: 0.8737\n",
      "Epoch 9/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [01:04<00:00,  2.67s/it]\n",
      "100%|██████████| 6/6 [00:14<00:00,  2.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2439.4627\n",
      "Validation Loss: 5439.6785\n",
      "Validation Accuracy: 0.9684\n",
      "Saved Best Model!\n",
      "Epoch 10/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [01:04<00:00,  2.71s/it]\n",
      "100%|██████████| 6/6 [00:14<00:00,  2.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1969.5945\n",
      "Validation Loss: 5258.2917\n",
      "Validation Accuracy: 0.9474\n",
      "Epoch 11/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [01:04<00:00,  2.70s/it]\n",
      "100%|██████████| 6/6 [00:14<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2080.6403\n",
      "Validation Loss: 5519.5949\n",
      "Validation Accuracy: 0.8632\n",
      "Epoch 12/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [01:04<00:00,  2.68s/it]\n",
      "100%|██████████| 6/6 [00:14<00:00,  2.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1834.6947\n",
      "Validation Loss: 5340.4864\n",
      "Validation Accuracy: 0.9895\n",
      "Saved Best Model!\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 12\n",
    "best_accuracy = 0.0\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "    \n",
    "    train_loss = train(model, train_loader, optimizer, device)\n",
    "    val_loss, val_accuracy = evaluate(model, test_loader, device)\n",
    "    \n",
    "    print(f\"Train Loss: {train_loss:.4f}\")\n",
    "    print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "    print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "    # Save the model if it has the best accuracy so far\n",
    "    if val_accuracy > best_accuracy:\n",
    "        best_accuracy = val_accuracy\n",
    "        torch.save(model.state_dict(), \"best_model_full.pth\")\n",
    "        print(\"Saved Best Model!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b9/t4lk8c451h5dmb3m5570wjvc0000gn/T/ipykernel_32691/3121772286.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"best_model_full.pth\"))\n",
      "100%|██████████| 6/6 [00:14<00:00,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 5340.4864\n",
      "Test Accuracy: 0.9895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"best_model_full.pth\"))\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_loss, test_accuracy = evaluate(model, test_loader, device)\n",
    "\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved predictions to submission_full_test_2.csv\n"
     ]
    }
   ],
   "source": [
    "# Inference and saving to CSV\n",
    "def predict_and_save(model, test_loader, device, output_file=\"submission.csv\"):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    seen_filenames = set()  # Track unique filenames to avoid duplicates\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels, bboxes in test_loader:  # Accepts images, labels, and bboxes\n",
    "            images = images.to(device)\n",
    "            class_outputs, bbox_outputs = model(images)\n",
    "            \n",
    "            # Get predicted class (1-based indexing)\n",
    "            class_preds = class_outputs.argmax(dim=1).cpu().numpy() + 1  \n",
    "            # Get bounding box predictions\n",
    "            bbox_preds = bbox_outputs.cpu().numpy()\n",
    "            \n",
    "            # Assuming filenames are stored as part of the dataset's DataFrame\n",
    "            for filename, class_id, bbox_pred, label, bbox_true in zip(\n",
    "                test_loader.dataset.data['filename'], class_preds, bbox_preds, labels.cpu().numpy(), bboxes.cpu().numpy()\n",
    "            ):\n",
    "                # Only add unique filenames\n",
    "                if filename not in seen_filenames:\n",
    "                    predictions.append([filename, class_id, *bbox_pred, label, *bbox_true])\n",
    "                    seen_filenames.add(filename)  # Mark this filename as seen\n",
    "    \n",
    "    # Save predictions to CSV\n",
    "    submission_df = pd.DataFrame(predictions, columns=[\n",
    "        \"filename\", \"pred_class_id\", \"pred_xmin\", \"pred_ymin\", \"pred_xmax\", \"pred_ymax\",\n",
    "        \"true_class_id\", \"true_xmin\", \"true_ymin\", \"true_xmax\", \"true_ymax\"\n",
    "    ])\n",
    "    submission_df.to_csv(output_file, index=False)\n",
    "    \n",
    "    print(f\"Saved predictions to {output_file}\")\n",
    "\n",
    "# Run the prediction and save function\n",
    "predict_and_save(model, test_loader, device, output_file=\"submission_full_test_2.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Custom dataset for validation/test set without labels\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, csv_file, img_dir, transform=None):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        filename = self.data.iloc[idx]['filename']\n",
    "        img_path = os.path.join(self.img_dir, filename)\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, filename  # Only return image and filename\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((255, 255)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Paths\n",
    "csv_file = '/Users/danielmartinezvillegas/Developer/master-ds/s_2/fda_2/cnn/cnn_practice/AF_dataset/test.csv'\n",
    "img_dir = '/Users/danielmartinezvillegas/Developer/master-ds/s_2/fda_2/cnn/cnn_practice/AF_dataset/images'\n",
    "\n",
    "# Create the dataset and loader\n",
    "validation_dataset = TestDataset(csv_file, img_dir, transform=data_transforms)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=16, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved predictions to validation_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "# Inference and saving to CSV for unlabeled validation/test set\n",
    "def predict_and_save_unlabeled(model, loader, device, output_file=\"validation_predictions.csv\"):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    seen_filenames = set()  # Track unique filenames to avoid duplicates\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, filenames in loader:  # Accepts images and filenames only\n",
    "            images = images.to(device)\n",
    "            class_outputs, bbox_outputs = model(images)\n",
    "            \n",
    "            # Get predicted class (1-based indexing)\n",
    "            class_preds = class_outputs.argmax(dim=1).cpu().numpy() + 1  \n",
    "            # Get bounding box predictions\n",
    "            bbox_preds = bbox_outputs.cpu().numpy()\n",
    "            \n",
    "            # Save predictions for each file\n",
    "            for filename, class_id, bbox_pred in zip(filenames, class_preds, bbox_preds):\n",
    "                # Only add unique filenames\n",
    "                if filename not in seen_filenames:\n",
    "                    predictions.append([filename, class_id, *bbox_pred])\n",
    "                    seen_filenames.add(filename)  # Mark this filename as seen\n",
    "    \n",
    "    # Save predictions to CSV\n",
    "    submission_df = pd.DataFrame(predictions, columns=[\n",
    "        \"filename\", \"pred_class_id\", \"pred_xmin\", \"pred_ymin\", \"pred_xmax\", \"pred_ymax\"\n",
    "    ])\n",
    "    submission_df.to_csv(output_file, index=False)\n",
    "    \n",
    "    print(f\"Saved predictions to {output_file}\")\n",
    "\n",
    "# Run the prediction and save function for validation/test data\n",
    "predict_and_save_unlabeled(model, validation_loader, device, output_file=\"validation_predictions.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-macos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

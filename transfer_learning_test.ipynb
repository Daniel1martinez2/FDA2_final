{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, models, transforms\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directory paths\n",
    "data_dir = 'AF_dataset'\n",
    "train_dir = os.path.join(data_dir, 'train')\n",
    "test_dir = os.path.join(data_dir, 'test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data transformations\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((255, 255)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # Pretrained VGG-16 mean and std\n",
    "])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize((255, 255)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Datasets\n",
    "train_dataset = datasets.ImageFolder(root=train_dir, transform=train_transforms)\n",
    "test_dataset = datasets.ImageFolder(root=test_dir, transform=test_transforms)\n",
    "\n",
    "# Data Loaders\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=4096, out_features=1000, bias=True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load VGG-16 model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = models.vgg16(pretrained=True)\n",
    "\n",
    "# Freeze all layers\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Modify the classifier part\n",
    "model.classifier[6] = nn.Linear(in_features=4096, out_features=2)\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.classifier[6].parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in tqdm(train_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * images.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    return epoch_loss\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(test_loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            \n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    epoch_loss = running_loss / len(test_loader.dataset)\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    return epoch_loss, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [01:23<00:00,  3.49s/it]\n",
      "100%|██████████| 6/6 [00:37<00:00,  6.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1549\n",
      "Validation Loss: 0.0126\n",
      "Validation Accuracy: 1.0000\n",
      "Saved Best Model!\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [01:22<00:00,  3.43s/it]\n",
      "100%|██████████| 6/6 [00:37<00:00,  6.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0304\n",
      "Validation Loss: 0.0059\n",
      "Validation Accuracy: 1.0000\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [01:23<00:00,  3.48s/it]\n",
      "100%|██████████| 6/6 [00:37<00:00,  6.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0194\n",
      "Validation Loss: 0.0051\n",
      "Validation Accuracy: 1.0000\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [01:22<00:00,  3.43s/it]\n",
      "100%|██████████| 6/6 [00:36<00:00,  6.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0117\n",
      "Validation Loss: 0.0048\n",
      "Validation Accuracy: 1.0000\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [01:22<00:00,  3.43s/it]\n",
      "100%|██████████| 6/6 [00:36<00:00,  6.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0079\n",
      "Validation Loss: 0.0042\n",
      "Validation Accuracy: 1.0000\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [01:22<00:00,  3.43s/it]\n",
      "100%|██████████| 6/6 [00:37<00:00,  6.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0086\n",
      "Validation Loss: 0.0044\n",
      "Validation Accuracy: 1.0000\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [01:22<00:00,  3.43s/it]\n",
      "100%|██████████| 6/6 [00:36<00:00,  6.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0081\n",
      "Validation Loss: 0.0026\n",
      "Validation Accuracy: 1.0000\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [01:21<00:00,  3.40s/it]\n",
      "100%|██████████| 6/6 [00:36<00:00,  6.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0057\n",
      "Validation Loss: 0.0026\n",
      "Validation Accuracy: 1.0000\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [01:22<00:00,  3.45s/it]\n",
      "100%|██████████| 6/6 [00:36<00:00,  6.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0093\n",
      "Validation Loss: 0.0024\n",
      "Validation Accuracy: 1.0000\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [01:22<00:00,  3.42s/it]\n",
      "100%|██████████| 6/6 [00:36<00:00,  6.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0064\n",
      "Validation Loss: 0.0018\n",
      "Validation Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 10\n",
    "best_accuracy = 0.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "    train_loss = train(model, train_loader, criterion, optimizer, device)\n",
    "    val_loss, val_accuracy = evaluate(model, test_loader, criterion, device)\n",
    "    \n",
    "    print(f\"Train Loss: {train_loss:.4f}\")\n",
    "    print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "    print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "    \n",
    "    # Save the model if it has the best accuracy so far\n",
    "    if val_accuracy > best_accuracy:\n",
    "        best_accuracy = val_accuracy\n",
    "        torch.save(model.state_dict(), \"best_model.pth\")\n",
    "        print(\"Saved Best Model!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b9/t4lk8c451h5dmb3m5570wjvc0000gn/T/ipykernel_49273/596005923.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"best_model.pth\"))\n",
      "100%|██████████| 6/6 [00:36<00:00,  6.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0126\n",
      "Test Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the best model saved during training (optional)\n",
    "model.load_state_dict(torch.load(\"best_model.pth\"))\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_loss, test_accuracy = evaluate(model, test_loader, criterion, device)\n",
    "\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Define path to the validation images\n",
    "validation_dir = 'AF_dataset/validation'\n",
    "\n",
    "# Define transformations (same as used during training)\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((255, 255)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Custom Dataset for unlabelled images\n",
    "class ValidationDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_files = os.listdir(root_dir)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_files[idx]\n",
    "        img_path = os.path.join(self.root_dir, img_name)\n",
    "        image = Image.open(img_path).convert(\"RGB\")  # Ensure image is in RGB format\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, img_name  # Return image and filename\n",
    "\n",
    "# Initialize the validation dataset and dataloader\n",
    "validation_dataset = ValidationDataset(root_dir=validation_dir, transform=val_transforms)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=1, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b9/t4lk8c451h5dmb3m5570wjvc0000gn/T/ipykernel_49273/2241060273.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"best_model.pth\", map_location=device))\n"
     ]
    }
   ],
   "source": [
    "# Load the best model (ensure device is set to 'mps' if using Apple Silicon GPU)\n",
    "model.load_state_dict(torch.load(\"best_model.pth\", map_location=device))\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Prepare to store predictions\n",
    "predictions = []\n",
    "\n",
    "# Perform inference on the validation set\n",
    "with torch.no_grad():\n",
    "    for images, filenames in validation_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # Get predicted class (1 for penguin, 2 for turtle)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        preds = preds.cpu().item() + 1  # Convert to 1-based class_id (1=Penguin, 2=Turtle)\n",
    "        \n",
    "        # Append the results in the format (filename, class_id)\n",
    "        for filename in filenames:\n",
    "            predictions.append((filename, preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file created successfully as 'submission.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert predictions to DataFrame\n",
    "submission_df = pd.DataFrame(predictions, columns=[\"filename\", \"class_id\"])\n",
    "\n",
    "# Save to CSV\n",
    "submission_df.to_csv(\"submission_TL.csv\", index=False)\n",
    "\n",
    "print(\"Submission file created successfully as 'submission.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reordered submission file saved as 'submission_reordered.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Expected order of filenames\n",
    "expected_filenames = [\n",
    "\t'image_id_004_.jpg',\n",
    "\t'image_id_010_.jpg',\n",
    "\t'image_id_016_.jpg',\n",
    "\t'image_id_024_.jpg',\n",
    "\t'image_id_033_.jpg',\n",
    "\t'image_id_034_.jpg',\n",
    "\t'image_id_037_.jpg',\n",
    "\t'image_id_038_.jpg',\n",
    "\t'image_id_043_.jpg',\n",
    "\t'image_id_050_.jpg',\n",
    "\t'image_id_054_.jpg',\n",
    "\t'image_id_066_.jpg',\n",
    "\t'image_id_073_.jpg',\n",
    "\t'image_id_075_.jpg',\n",
    "\t'image_id_076_.jpg',\n",
    "\t'image_id_086_.jpg',\n",
    "\t'image_id_090_.jpg',\n",
    "\t'image_id_092_.jpg',\n",
    "\t'image_id_106_.jpg',\n",
    "\t'image_id_110_.jpg',\n",
    "\t'image_id_112_.jpg',\n",
    "\t'image_id_115_.jpg',\n",
    "\t'image_id_122_.jpg',\n",
    "\t'image_id_124_.jpg',\n",
    "\t'image_id_129_.jpg',\n",
    "\t'image_id_154_.jpg',\n",
    "\t'image_id_156_.jpg',\n",
    "\t'image_id_174_.jpg',\n",
    "\t'image_id_177_.jpg',\n",
    "\t'image_id_180_.jpg',\n",
    "\t'image_id_183_.jpg',\n",
    "\t'image_id_185_.jpg',\n",
    "\t'image_id_187_.jpg',\n",
    "\t'image_id_189_.jpg',\n",
    "\t'image_id_190_.jpg',\n",
    "\t'image_id_193_.jpg',\n",
    "\t'image_id_208_.jpg',\n",
    "\t'image_id_212_.jpg',\n",
    "\t'image_id_221_.jpg',\n",
    "\t'image_id_223_.jpg',\n",
    "\t'image_id_224_.jpg',\n",
    "\t'image_id_228_.jpg',\n",
    "\t'image_id_239_.jpg',\n",
    "\t'image_id_247_.jpg',\n",
    "\t'image_id_250_.jpg',\n",
    "\t'image_id_263_.jpg',\n",
    "\t'image_id_264_.jpg',\n",
    "\t'image_id_265_.jpg',\n",
    "\t'image_id_268_.jpg',\n",
    "\t'image_id_273_.jpg',\n",
    "\t'image_id_287_.jpg',\n",
    "\t'image_id_304_.jpg',\n",
    "\t'image_id_307_.jpg',\n",
    "\t'image_id_310_.jpg',\n",
    "\t'image_id_312_.jpg',\n",
    "\t'image_id_315_.jpg',\n",
    "\t'image_id_328_.jpg',\n",
    "\t'image_id_329_.jpg',\n",
    "\t'image_id_337_.jpg',\n",
    "\t'image_id_339_.jpg',\n",
    "\t'image_id_344_.jpg',\n",
    "\t'image_id_348_.jpg',\n",
    "\t'image_id_352_.jpg',\n",
    "\t'image_id_357_.jpg',\n",
    "\t'image_id_365_.jpg',\n",
    "\t'image_id_369_.jpg',\n",
    "\t'image_id_370_.jpg',\n",
    "\t'image_id_377_.jpg',\n",
    "\t'image_id_388_.jpg',\n",
    "\t'image_id_389_.jpg',\n",
    "\t'image_id_390_.jpg',\n",
    "\t'image_id_394_.jpg',\n",
    "\t'image_id_403_.jpg',\n",
    "\t'image_id_410_.jpg',\n",
    "\t'image_id_419_.jpg',\n",
    "\t'image_id_430_.jpg',\n",
    "\t'image_id_434_.jpg',\n",
    "\t'image_id_442_.jpg',\n",
    "\t'image_id_445_.jpg',\n",
    "\t'image_id_458_.jpg',\n",
    "\t'image_id_462_.jpg',\n",
    "\t'image_id_471_.jpg',\n",
    "\t'image_id_474_.jpg',\n",
    "\t'image_id_477_.jpg',\n",
    "\t'image_id_492_.jpg',\n",
    "\t'image_id_495_.jpg',\n",
    "\t'image_id_498_.jpg',\n",
    "\t'image_id_500_.jpg',\n",
    "\t'image_id_514_.jpg',\n",
    "\t'image_id_519_.jpg',\n",
    "\t'image_id_524_.jpg',\n",
    "\t'image_id_527_.jpg',\n",
    "\t'image_id_537_.jpg',\n",
    "\t'image_id_545_.jpg',\n",
    "\t'image_id_548_.jpg',\n",
    "\t'image_id_551_.jpg',\n",
    "\t'image_id_563_.jpg',\n",
    "\t'image_id_571_.jpg',\n",
    "\n",
    "]\n",
    "\n",
    "# Load the generated submission DataFrame\n",
    "submission_df = pd.read_csv(\"submission_TL.csv\")\n",
    "\n",
    "# Reorder based on expected filenames\n",
    "submission_df[\"filename\"] = pd.Categorical(submission_df[\"filename\"], categories=expected_filenames, ordered=True)\n",
    "submission_df = submission_df.sort_values(\"filename\")\n",
    "\n",
    "# Save the reordered submission file\n",
    "submission_df.to_csv(\"submission_reordered.csv\", index=False)\n",
    "print(\"Reordered submission file saved as 'submission_reordered.csv'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-macos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import models, transforms\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "import shutil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directory paths\n",
    "data_dir = '' # root\n",
    "train_dir = os.path.join(data_dir, 'train')\n",
    "validation_dir = os.path.join(data_dir, 'test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_info = pd.read_csv('train.csv')\n",
    "\n",
    "X = train_info[['filename', 'xmin', 'ymin', 'xmax', 'ymax']]\n",
    "y = train_info['class_id']\n",
    "\n",
    "data = pd.concat([X, y], axis=1)\t\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "train_data = pd.concat([X_train, y_train], axis=1)\n",
    "validation_data = pd.concat([X_val, y_val], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_test_img_folder(train_df, test_df):\n",
    "    splits = {'train': train_df, 'test': test_df}\n",
    "    for split, df in splits.items():\n",
    "        for i, row in df.iterrows():\n",
    "            source_file = f'images/{row[\"filename\"]}'\n",
    "            class_name = 'pinguin' if row['class_id'] == 1 else 'turtle'\n",
    "            destination_folder = f'data/{split}'\n",
    "            os.makedirs(destination_folder, exist_ok=True)\n",
    "            destination_file = os.path.join(destination_folder)\n",
    "            shutil.copy(source_file, destination_file)\n",
    "\n",
    "\n",
    "create_train_test_img_folder(train_data, validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = 'data'\n",
    "train_dir = os.path.join(root_dir, 'train')\n",
    "validation_dir = os.path.join(root_dir, 'validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoundingBoxDataset(Dataset):\n",
    "    def __init__(self, data, root_dir, transform=None):\n",
    "        self.data = data\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        img_name = os.path.join(self.root_dir, row['filename'])\n",
    "        image = plt.imread(img_name)\n",
    "        \n",
    "        # Apply transformations if any\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Extract bounding box coordinates\n",
    "        bbox = torch.tensor([row['xmin'], row['ymin'], row['xmax'], row['ymax']])\n",
    "        \n",
    "        # Extract class label\n",
    "        label = torch.tensor(row['class_id'] - 1)  # Subtract 1 to make labels 0-based\n",
    "\n",
    "        return image, label, bbox\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data transformations\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.Resize((255, 255)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # Pretrained VGG-16 mean and std\n",
    "])\n",
    "\n",
    "validation_transforms = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((255, 255)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train and test data\n",
    "train_dataset = BoundingBoxDataset(train_data, root_dir=train_dir, transform=train_transforms)\n",
    "validation_dataset = BoundingBoxDataset(validation_data, root_dir=validation_dir, transform=validation_transforms)\n",
    "\n",
    "# Data loaders\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained VGG-16 model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "base_model = models.vgg16(pretrained=True)\n",
    "\n",
    "# Freeze the base model layers\n",
    "for param in base_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Modify the classifier for dual outputs\n",
    "class MultiTaskVGG16(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiTaskVGG16, self).__init__()\n",
    "        \n",
    "        # Base feature extractor\n",
    "        self.features = base_model.features\n",
    "        self.avgpool = base_model.avgpool\n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        # Shared fully connected layers\n",
    "        self.shared_fc = nn.Sequential(\n",
    "            nn.Linear(512 * 7 * 7, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5)\n",
    "        )\n",
    "        \n",
    "        # Classification head\n",
    "        self.classifier = nn.Linear(4096, 2)  # For 2 classes: penguin and turtle\n",
    "        \n",
    "        # Bounding box regression head\n",
    "        self.regressor = nn.Linear(4096, 4)  # For 4 coordinates: xmin, ymin, xmax, ymax\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.shared_fc(x)\n",
    "        \n",
    "        class_output = self.classifier(x)\n",
    "        bbox_output = self.regressor(x)\n",
    "        \n",
    "        return class_output, bbox_output\n",
    "\n",
    "# Initialize model\n",
    "model = MultiTaskVGG16().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss functions\n",
    "classification_criterion = nn.CrossEntropyLoss()\n",
    "regression_criterion = nn.MSELoss()\n",
    "\n",
    "# Optimizer (only fine-tuning the final layers)\n",
    "optimizer = Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train(model, train_loader, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels, bboxes in tqdm(train_loader):\n",
    "        images, labels, bboxes = images.to(device), labels.to(device), bboxes.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        class_outputs, bbox_outputs = model(images)\n",
    "        \n",
    "        # Compute losses\n",
    "        class_loss = classification_criterion(class_outputs, labels)\n",
    "        bbox_loss = regression_criterion(bbox_outputs, bboxes.float())\n",
    "        loss = class_loss + bbox_loss  # Combine losses\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * images.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    return epoch_loss\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate(model, test_loader, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    all_preds, all_labels = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels, bboxes in tqdm(test_loader):\n",
    "            images, labels, bboxes = images.to(device), labels.to(device), bboxes.to(device)\n",
    "            \n",
    "            class_outputs, bbox_outputs = model(images)\n",
    "            \n",
    "            # Compute losses\n",
    "            class_loss = classification_criterion(class_outputs, labels)\n",
    "            bbox_loss = regression_criterion(bbox_outputs, bboxes.float())\n",
    "            loss = class_loss + bbox_loss\n",
    "            \n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            \n",
    "            # Store predictions and labels for accuracy calculation\n",
    "            preds = class_outputs.argmax(dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    epoch_loss = running_loss / len(test_loader.dataset)\n",
    "    return epoch_loss, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "num_epochs = 12\n",
    "best_accuracy = 0.0\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "    \n",
    "    train_loss = train(model, train_loader, optimizer, device)\n",
    "    val_loss, val_accuracy = evaluate(model, validation_loader, device)\n",
    "    \n",
    "    print(f\"Train Loss: {train_loss:.4f}\")\n",
    "    print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "    print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "    # Save the model if it has the best accuracy so far\n",
    "    if val_accuracy > best_accuracy:\n",
    "        best_accuracy = val_accuracy\n",
    "        torch.save(model.state_dict(), \"best_model_full.pth\")\n",
    "        print(\"Saved Best Model!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"best_model_full.pth\"))\n",
    "\n",
    "# Evaluate on the test set\n",
    "validation_loss, validation_accuracy = evaluate(model, validation_loader, device)\n",
    "\n",
    "print(f\"Test Loss: {validation_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {validation_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Inference and saving to CSV\n",
    "# def predict_and_save(model, validation_loader, device, output_file=\"submission.csv\"):\n",
    "#     model.eval()\n",
    "#     predictions = []\n",
    "#     seen_filenames = set()  # Track unique filenames to avoid duplicates\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         for images, labels, bboxes in validation_loader:  # Accepts images, labels, and bboxes\n",
    "#             images = images.to(device)\n",
    "#             class_outputs, bbox_outputs = model(images)\n",
    "            \n",
    "#             # Get predicted class (1-based indexing)\n",
    "#             class_preds = class_outputs.argmax(dim=1).cpu().numpy() + 1  \n",
    "#             # Get bounding box predictions\n",
    "#             bbox_preds = bbox_outputs.cpu().numpy()\n",
    "            \n",
    "#             # Assuming filenames are stored as part of the dataset's DataFrame\n",
    "#             for filename, class_id, bbox_pred, label, bbox_true in zip(\n",
    "#                 validation_loader.dataset.data['filename'], class_preds, bbox_preds, labels.cpu().numpy(), bboxes.cpu().numpy()\n",
    "#             ):\n",
    "#                 # Only add unique filenames\n",
    "#                 if filename not in seen_filenames:\n",
    "#                     predictions.append([filename, class_id, *bbox_pred, label, *bbox_true])\n",
    "#                     seen_filenames.add(filename)  # Mark this filename as seen\n",
    "    \n",
    "#     # Save predictions to CSV\n",
    "#     submission_df = pd.DataFrame(predictions, columns=[\n",
    "#         \"filename\", \"pred_class_id\", \"pred_xmin\", \"pred_ymin\", \"pred_xmax\", \"pred_ymax\",\n",
    "#         \"true_class_id\", \"true_xmin\", \"true_ymin\", \"true_xmax\", \"true_ymax\"\n",
    "#     ])\n",
    "#     submission_df.to_csv(output_file, index=False)\n",
    "    \n",
    "#     print(f\"Saved predictions to {output_file}\")\n",
    "\n",
    "# # Run the prediction and save function\n",
    "# predict_and_save(model, train_loader, device, output_file=\"submission_full_test_2.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Custom dataset for validation/test set without labels\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, csv_file, img_dir, transform=None):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        filename = self.data.iloc[idx]['filename']\n",
    "        img_path = os.path.join(self.img_dir, filename)\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, filename  # Only return image and filename\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((255, 255)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Paths\n",
    "csv_file = 'test.csv'\n",
    "img_dir = 'images'\n",
    "\n",
    "# Create the dataset and loader\n",
    "test_dataset = TestDataset(csv_file, img_dir, transform=data_transforms)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Inference and saving to CSV for unlabeled validation/test set\n",
    "# def predict_and_save_unlabeled(model, loader, device, output_file=\"test_predictions.csv\"):\n",
    "#     model.eval()\n",
    "#     predictions = []\n",
    "#     seen_filenames = set()  # Track unique filenames to avoid duplicates\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         for images, filenames in loader:  # Accepts images and filenames only\n",
    "#             images = images.to(device)\n",
    "#             class_outputs, bbox_outputs = model(images)\n",
    "            \n",
    "#             # Get predicted class (1-based indexing)\n",
    "#             class_preds = class_outputs.argmax(dim=1).cpu().numpy() + 1  \n",
    "#             # Get bounding box predictions\n",
    "#             bbox_preds = bbox_outputs.cpu().numpy()\n",
    "            \n",
    "#             # Save predictions for each file\n",
    "#             for filename, class_id, bbox_pred in zip(filenames, class_preds, bbox_preds):\n",
    "#                 # Only add unique filenames\n",
    "#                 if filename not in seen_filenames:\n",
    "#                     predictions.append([filename, class_id, *bbox_pred])\n",
    "#                     seen_filenames.add(filename)  # Mark this filename as seen\n",
    "    \n",
    "#     # Save predictions to CSV\n",
    "#     submission_df = pd.DataFrame(predictions, columns=[\n",
    "#         \"filename\", \"pred_class_id\", \"pred_xmin\", \"pred_ymin\", \"pred_xmax\", \"pred_ymax\"\n",
    "#     ])\n",
    "#     submission_df.to_csv(output_file, index=False)\n",
    "    \n",
    "#     print(f\"Saved predictions to {output_file}\")\n",
    "\n",
    "# # Run the prediction and save function for validation/test data\n",
    "# predict_and_save_unlabeled(model, test_loader, device, output_file=\"test_predictions.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **CNN Personalizado**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En este paso definimos el dataset.\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join('data/train', self.dataframe.iloc[idx, 0])\n",
    "        image = plt.imread(img_name)\n",
    "        label = self.dataframe.iloc[idx, -1] \n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, se definen las transformaciones necesarias para realizar el Data Augmentation y la normalización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),  \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  \n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección, realizamos la creación de las instancias de los conjuntos de datos y los data loaders para realizar el entrenamiento y la validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(train_data, transform=transform)\n",
    "validation_dataset = CustomDataset(validation_data, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este punto, definimos el modelo de red neuronal personalizado, la estructura propuesta es una tal que:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class CustomCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * 28 * 28, 128)  \n",
    "        self.fc2 = nn.Linear(128, 2)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(nn.functional.relu(self.conv1(x)))\n",
    "        x = self.pool(nn.functional.relu(self.conv2(x)))\n",
    "        x = self.pool(nn.functional.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 64 * 28 * 28)  \n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicialización del modelo, la función de perdida y el optimizador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CustomCNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teniendo en cuenta que el Cross Entropy Loss es una función que espera que las clases estén codificados en 0 y 1, procedemos a realizar la codificaicón previa. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores únicos en train_data['class_id']: [0 1]\n",
      "Valores únicos en validation_data['class_id']: [1 0]\n"
     ]
    }
   ],
   "source": [
    "train_data['class_id'] = train_data['class_id'].replace({1: 0, 2: 1})\n",
    "\n",
    "validation_data['class_id'] = validation_data['class_id'].replace({1: 0, 2: 1})\n",
    "\n",
    "print(\"Valores únicos en train_data['class_id']:\", train_data['class_id'].unique())\n",
    "print(\"Valores únicos en validation_data['class_id']:\", validation_data['class_id'].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, realizamos el entrenamiento del modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:17<00:00,  1.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.8315, Accuracy: 0.6127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:12<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Loss: 0.5461, Accuracy: 0.7128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:12<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Loss: 0.4594, Accuracy: 0.8028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:12<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Loss: 0.3422, Accuracy: 0.8622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:14<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Loss: 0.2816, Accuracy: 0.8771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:14<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Loss: 0.1803, Accuracy: 0.9266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:13<00:00,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Loss: 0.1233, Accuracy: 0.9600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:14<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Loss: 0.0789, Accuracy: 0.9735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:14<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Loss: 0.0438, Accuracy: 0.9870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:14<00:00,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Loss: 0.0208, Accuracy: 0.9974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def train_model(model, train_loader, criterion, optimizer, num_epochs=10):\n",
    "    model.train()  \n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        running_accuracy = 0.0\n",
    "        \n",
    "        for images, labels in tqdm(train_loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()  \n",
    "            outputs = model(images)  \n",
    "            \n",
    "            loss = criterion(outputs, labels) \n",
    "            loss.backward()  \n",
    "            optimizer.step() \n",
    "            \n",
    "            \n",
    "            _, predicted = torch.max(outputs, 1)  \n",
    "            correct = (predicted == labels).sum().item()  \n",
    "            accuracy = correct / labels.size(0)  \n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            running_accuracy += accuracy\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_accuracy = running_accuracy / len(train_loader)  \n",
    "        \n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}')\n",
    "\n",
    "\n",
    "train_model(model, train_loader, criterion, optimizer, num_epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 36\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Evaluación del modelo \u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m evaluate_model(model, \u001b[43mtest_loader\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_loader' is not defined"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()  \n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            # Imprimir el tipo y la longitud del batch\n",
    "            print(f'Batch: {batch}, Type: {type(batch)}, Length: {len(batch)}')\n",
    "            \n",
    "            # Desempaquetar el batch según su longitud\n",
    "            if len(batch) == 2:\n",
    "                images, labels = batch\n",
    "            elif len(batch) > 2:\n",
    "                images, labels = batch[0], batch[1]  \n",
    "            else:\n",
    "                print(\"Unexpected batch format:\", batch)\n",
    "                continue\n",
    "\n",
    "            # Revisión de característica de images y labels \n",
    "            if isinstance(images, tuple) or isinstance(labels, tuple):\n",
    "                print(\"Images or labels are tuples. Check your dataset.\")\n",
    "                continue\n",
    "            \n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Evaluación del modelo \n",
    "\n",
    "evaluate_model(model, test_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay que pegarle la cabeza de la clasificación a esta parte. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "images",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
